# -*- coding: utf-8 -*-
import streamlit as st
import speech_recognition as sr
from io import BytesIO
from pydub import AudioSegment
from gtts import gTTS
import json
import base64
import os

st.set_page_config(page_title="Tr∆∞ng V∆∞∆°ng Garden - Voice Assistant", layout="centered")

st.markdown("<h2 style='text-align:center;'>CH√ÄO M·ª™NG B·∫†N ƒê·∫æN TR∆ØNG V∆Ø∆†NG GARDEN</h2>", unsafe_allow_html=True)
st.markdown("<h4 style='text-align:center;'>TR·ª¢ L√ù A.I B·∫∞NG GI·ªåNG N√ìI TVG</h4>", unsafe_allow_html=True)

st.markdown("""
**H∆∞·ªõng d·∫´n ng·∫Øn:**
1) Tr√¨nh duy·ªát s·∫Ω t·ª± ph√°t **l·ªùi ch√†o gi·ªõi thi·ªáu** khi m·ªü app.
2) Nh·∫•n **B·∫•m ƒë·ªÉ h·ªèi**, ghi √¢m c√¢u h·ªèi (upload file audio).
3) Tr·ª£ l√Ω tr·∫£ l·ªùi b·∫±ng √¢m thanh.
4) Nh·∫•n **K·∫øt th√∫c** ƒë·ªÉ ch√†o t·∫°m bi·ªát.
""")

# ---- Load FAQ JSON ----
def find_answer(user_text):
    try:
        with open("faq_garden.json", encoding="utf-8") as f:
            faq_data = json.load(f)
    except Exception:
        return "Xin l·ªói, hi·ªán t·∫°i t√¥i kh√¥ng th·ªÉ truy c·∫≠p d·ªØ li·ªáu t∆∞ v·∫•n."

    for item in faq_data.get("faq", []):
        for keyword in item.get("question", []):
            if keyword.lower() in user_text.lower():
                return item.get("answer", "")
    return ("Xin l·ªói, t√¥i ch∆∞a hi·ªÉu c√¢u h·ªèi c·ªßa b·∫°n. "
            "B·∫°n c√≥ th·ªÉ h·ªèi v·ªÅ gi·ªù m·ªü c·ª≠a, gi√° v√©, tr·∫£i nghi·ªám, ·∫©m th·ª±c, khuy·∫øn m√£i ho·∫∑c li√™n h·ªá.")

# ---- Ph√°t audio b·∫±ng HTML5 (tr√¨nh duy·ªát) ----
def play_audio_file(file_path):
    if not os.path.exists(file_path):
        st.error(f"Kh√¥ng t√¨m th·∫•y file {file_path}")
        return
    audio_file = open(file_path, "rb").read()
    b64_audio = base64.b64encode(audio_file).decode()
    audio_html = f"""
        <audio autoplay="true" controls>
        <source src="data:audio/mp3;base64,{b64_audio}" type="audio/mp3">
        Your browser does not support the audio element.
        </audio>
    """
    st.markdown(audio_html, unsafe_allow_html=True)

# ---- STT t·ª´ file audio ----
def transcribe_audio(uploaded_file):
    if uploaded_file is None:
        return None
    file_bytes = uploaded_file.read()
    audio = AudioSegment.from_file(BytesIO(file_bytes))
    wav_io = BytesIO()
    audio.export(wav_io, format="wav")
    wav_io.seek(0)
    
    recognizer = sr.Recognizer()
    with sr.AudioFile(wav_io) as source:
        audio_data = recognizer.record(source)
        try:
            text = recognizer.recognize_google(audio_data, language='vi-VN')
            return text
        except sr.UnknownValueError:
            return "T√¥i kh√¥ng nghe r√µ, b·∫°n vui l√≤ng n√≥i l·∫°i nh√©!"
        except sr.RequestError:
            return "Hi·ªán t·∫°i kh√¥ng th·ªÉ k·∫øt n·ªëi d·ªãch v·ª• STT."

# ---- Ph√°t TTS t·ª± ƒë·ªông ----
def speak_text(text, temp_file="temp_answer.mp3"):
    tts = gTTS(text=text, lang="vi")
    tts.save(temp_file)
    play_audio_file(temp_file)

# ---- AUTO PH√ÅT L·ªúI CH√ÄO KHI M·ªû APP ----
if 'intro_played' not in st.session_state:
    st.session_state.intro_played = False

if not st.session_state.intro_played:
    intro_text = (
        "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω Voice AI Tr∆∞ng V∆∞∆°ng Garden. "
        "Khu tr·∫£i nghi·ªám c·ªßa ch√∫ng t√¥i c√≥ nhi·ªÅu d·ªãch v·ª• th√∫ v·ªã: "
        "V√© tham quan, V∆∞·ªùn c√¢y nhi·ªát ƒë·ªõi, V∆∞·ªùn chim Aviary, S·ªü th√∫ ƒÉn chay, "
        "Th√°c n∆∞·ªõc Apsara, Su·ªëi ƒë√° M·ªì C√¥i, B·∫øn Thi√™n C·∫ßm, Nh√† tre c·ªông ƒë·ªìng, "
        "V∆∞·ªùn t∆∞·ª£ng c·∫£nh quan, H·ªì Thi√™n Nga, C·∫ßu Ki·ªÅu. "
        "C√°c ho·∫°t ƒë·ªông tr·∫£i nghi·ªám: c∆∞·ª°i ng·ª±a, H·ªì b∆°i Pool Party, xe ƒë·∫°p ƒë√¥i v√† ƒë∆°n, "
        "xe ƒëi·ªán tham quan, thuy·ªÅn Thi√™n Nga, thuy·ªÅn SUP, KAYAK, "
        "Tr∆∞·ª£t phao c·∫ßu v·ªìng, xe ƒëua Gokart. "
        "·∫®m th·ª±c t·∫°i nh√† h√†ng Champa ph·ª•c v·ª• ·∫©m th·ª±c ƒë·ªãa ph∆∞∆°ng, "
        "b√£i ƒë·ªó xe mi·ªÖn ph√≠ v√† nhi·ªÅu g√≥c checkin. "
        "B·∫°n c√≥ th·ªÉ h·ªèi t√¥i v·ªÅ: gi·ªù m·ªü c·ª≠a, gi√° v√©, tr·∫£i nghi·ªám, khuy·∫øn m√£i, ·∫©m th·ª±c ho·∫∑c li√™n h·ªá."
    )
    speak_text(intro_text, "intro.mp3")
    st.session_state.intro_played = True

# ---- UI ----
col1, col2, col3 = st.columns([1,1,1])

# B·∫•m ƒë·ªÉ h·ªèi (upload audio)
uploaded_audio = col2.file_uploader("üé§ B·∫•m ƒë·ªÉ h·ªèi", type=["wav","mp3","m4a","webm"], key="user_audio")

if uploaded_audio is not None:
    user_text = transcribe_audio(uploaded_audio)
    st.info(f"B·∫°n n√≥i: {user_text}")
    answer_text = find_answer(user_text)
    st.success(f"Tr·ª£ l√Ω tr·∫£ l·ªùi: {answer_text}")
    speak_text(answer_text)

# K·∫øt th√∫c
if col3.button("‚èπ K·∫øt th√∫c"):
    farewell_text = "C·∫£m ∆°n b·∫°n ƒë√£ s·ª≠ d·ª•ng Tr·ª£ l√Ω Tr∆∞ng V∆∞∆°ng Garden. Ch√†o t·∫°m bi·ªát!"
    st.success(farewell_text)
    speak_text(farewell_text, "farewell.mp3")
