# -*- coding: utf-8 -*-
import streamlit as st
import json
from pathlib import Path

st.set_page_config(page_title="Tr∆∞ng V∆∞∆°ng Garden - Voice Assistant (Free)", layout="centered")

# ---------- Load FAQ ----------
FAQ_PATH = Path("faq_garden.json")
if not FAQ_PATH.exists():
    st.error("Kh√¥ng t√¨m th·∫•y file faq_garden.json trong c√πng th∆∞ m·ª•c.")
    st.stop()

with open(FAQ_PATH, encoding="utf-8") as f:
    faq_data = json.load(f)

def find_answer(user_text: str) -> str:
    for item in faq_data.get("faq", []):
        for kw in item.get("question", []):
            if kw.lower() in user_text.lower():
                return item.get("answer", "")
    return ("Xin l·ªói, t√¥i ch∆∞a hi·ªÉu c√¢u h·ªèi c·ªßa b·∫°n. "
            "B·∫°n c√≥ th·ªÉ h·ªèi v·ªÅ gi·ªù m·ªü c·ª≠a, gi√° v√©, tr·∫£i nghi·ªám, ·∫©m th·ª±c, khuy·∫øn m√£i ho·∫∑c li√™n h·ªá.")

# ---------- UI ----------
st.markdown("<h2 style='text-align:center;'>CH√ÄO M·ª™NG B·∫†N ƒê·∫æN TR∆ØNG V∆Ø∆†NG GARDEN</h2>", unsafe_allow_html=True)
st.markdown("<h4 style='text-align:center;'>TR·ª¢ L√ù A.I B·∫∞NG GI·ªåNG N√ìI TVG (MI·ªÑN PH√ç)</h4>", unsafe_allow_html=True)
st.markdown("<p style='text-align:center; color: gray;'>S·∫£n ph·∫©m do nh√≥m h·ªçc sinh CLB L·∫≠p tr√¨nh l·ªõp 7C</p>", unsafe_allow_html=True)

st.write("---")
st.write("H∆∞·ªõng d·∫´n ng·∫Øn: 1) Nh·∫•n **Ph√°t l·ªùi ch√†o** ƒë·ªÉ nghe gi·ªõi thi·ªáu. 2) Nh·∫•n **B·∫•m ƒë·ªÉ h·ªèi**, n√≥i c√¢u h·ªèi. 3) Tr·ª£ l√Ω tr·∫£ l·ªùi b·∫±ng √¢m thanh. 4) Nh·∫•n **K·∫øt th√∫c** ƒë·ªÉ ch√†o t·∫°m bi·ªát.")

col1, col2, col3 = st.columns([1,1,1])

with col1:
    if st.button("‚ñ∂Ô∏è Ph√°t l·ªùi ch√†o"):
        # khi ng∆∞·ªùi b·∫•m, front-end s·∫Ω t·ª± ƒë·ªçc ƒëo·∫°n INTRO (JS s·∫Ω th·ª±c thi)
        st.experimental_set_query_params(action="play_intro")
        st.success("ƒê√£ g·ª≠i l·ªánh ph√°t l·ªùi ch√†o (tr√¨nh duy·ªát s·∫Ω ƒë·ªçc).")

with col2:
    # n√∫t request start ‚Äî front-end s·∫Ω d√πng Web Speech ƒë·ªÉ b·∫Øt mic
    if st.button("üé§ B·∫•m ƒë·ªÉ h·ªèi"):
        st.experimental_set_query_params(action="start_listen")
        st.success("B·∫°n c√≥ th·ªÉ b·∫Øt ƒë·∫ßu n√≥i ‚Äî tr√¨nh duy·ªát s·∫Ω ghi √¢m v√† nh·∫≠n d·∫°ng.")

with col3:
    if st.button("‚èπ K·∫øt th√∫c"):
        st.experimental_set_query_params(action="stop_and_bye")
        st.success("K·∫øt th√∫c phi√™n. Tr√¨nh duy·ªát s·∫Ω ƒë·ªçc l·ªùi t·∫°m bi·ªát.")

st.write("---")

# placeholders for displaying recognized text and assistant reply
user_txt_ph = st.empty()
assistant_txt_ph = st.empty()

# This component embeds client-side JS that:
# - listens to URL query param changes (action) and triggers Web Speech API accordingly
# - does STT in browser, then POST the recognized text back to Streamlit via fetch to '/streamlit-server' is not possible
# Instead, we'll use the streamlit javascript-to-python communication using window.parent.postMessage
# The HTML below uses the Streamlit component protocol to send the recognized text back to Streamlit.
#
# The component returns the last recognized text as the component return value.
#
from streamlit.components.v1 import html

COMPONENT_HTML = f"""
<!doctype html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>TVG Voice Client</title>
  </head>
  <body>
    <script>
      // Utility to send value back into Streamlit
      function sendToStreamlit(value) {{
        const msg = {{isStreamlitMessage: true, type: "streamlit:setComponentValue", value: value}};
        window.parent.postMessage(msg, "*");
      }}

      // Read query param to decide action (start_listen, play_intro, stop_and_bye)
      function getAction() {{
        try {{
          const params = new URLSearchParams(window.location.search);
          return params.get("action");
        }} catch(e) {{
          return null;
        }}
      }}

      // Speech synthesis (TTS) via browser
      function speak(text) {{
        if (!("speechSynthesis" in window)) {{
          alert("Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ SpeechSynthesis.");
          return;
        }}
        const ut = new SpeechSynthesisUtterance(text);
        ut.lang = "vi-VN";
        // optional: choose voice if available
        const voices = speechSynthesis.getVoices();
        // choose first vi voice if present
        for (let v of voices) {{
          if (v.lang && v.lang.startsWith("vi")) {{
            ut.voice = v;
            break;
          }}
        }}
        speechSynthesis.cancel();
        speechSynthesis.speak(ut);
      }}

      // Web Speech API for recognition
      let recognition = null;
      function startRecognition() {{
        if (!("webkitSpeechRecognition" in window) && !("SpeechRecognition" in window)) {{
          alert("Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ Web Speech API. H√£y d√πng Chrome ho·∫∑c Edge.");
          sendToStreamlit("");
          return;
        }}
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        recognition = new SpeechRecognition();
        recognition.lang = "vi-VN";
        recognition.interimResults = false;
        recognition.maxAlternatives = 1;
        recognition.onresult = function(event) {{
          const text = event.results[0][0].transcript;
          // send recognized text to Streamlit
          sendToStreamlit(text);
        }};
        recognition.onerror = function(event) {{
          console.log("SpeechRecognition error", event);
          sendToStreamlit("");
        }};
        recognition.onend = function() {{
          // ended
        }};
        recognition.start();
      }}

      // parse action and run
      const action = getAction();
      if (action === "play_intro") {{
        const intro = {json.dumps("""Xin ch√†o! T√¥i l√† tr·ª£ l√Ω Voice AI Tr∆∞ng V∆∞∆°ng Garden. Khu tr·∫£i nghi·ªám c·ªßa ch√∫ng t√¥i c√≥ nhi·ªÅu d·ªãch v·ª• th√∫ v·ªã: V√© tham quan, V∆∞·ªùn c√¢y nhi·ªát ƒë·ªõi, V∆∞·ªùn chim Aviary, S·ªü th√∫ ƒÉn chay, Th√°c n∆∞·ªõc Apsara, Su·ªëi ƒë√° M·ªì C√¥i, B·∫øn Thi√™n C·∫ßm, Nh√† tre c·ªông ƒë·ªìng, V∆∞·ªùn t∆∞·ª£ng c·∫£nh quan, H·ªì Thi√™n Nga, C·∫ßu Ki·ªÅu. C√°c ho·∫°t ƒë·ªông tr·∫£i nghi·ªám: c∆∞·ª°i ng·ª±a, H·ªì b∆°i Pool Party, xe ƒë·∫°p ƒë√¥i v√† ƒë∆°n, xe ƒëi·ªán tham quan, thuy·ªÅn Thi√™n Nga, thuy·ªÅn SUP, KAYAK, Tr∆∞·ª£t phao c·∫ßu v·ªìng, xe ƒëua Gokart. ·∫®m th·ª±c t·∫°i nh√† h√†ng Champa ph·ª•c v·ª• ·∫©m th·ª±c ƒë·ªãa ph∆∞∆°ng, b√£i ƒë·ªó xe mi·ªÖn ph√≠ v√† nhi·ªÅu g√≥c checkin. B·∫°n c√≥ th·ªÉ h·ªèi t√¥i v·ªÅ: gi·ªù m·ªü c·ª≠a, gi√° v√©, tr·∫£i nghi·ªám, khuy·∫øn m√£i, ·∫©m th·ª±c ho·∫∑c li√™n h·ªá.""" )};
        speak(intro);
        // reset action param by updating history (so button can be pressed again)
        history.replaceState(null, "", window.location.pathname);
        // send empty to not trigger processing
        sendToStreamlit("");
      }} else if (action === "start_listen") {{
        startRecognition();
        // reset query
        history.replaceState(null, "", window.location.pathname);
      }} else if (action === "stop_and_bye") {{
        speak("C·∫£m ∆°n b·∫°n ƒë√£ tham quan Tr∆∞ng V∆∞∆°ng Garden. H·∫πn g·∫∑p l·∫°i!");
        history.replaceState(null, "", window.location.pathname);
        sendToStreamlit("__STOP__");
      }} else {{
        // no action -> do nothing
        sendToStreamlit("");
      }}
    </script>
  </body>
</html>
"""

# The component returns a string: recognized text or special flag
result = html(COMPONENT_HTML, height=0)  # height=0 hides iframe chrome

# When result is not empty, act: if __STOP__ -> speak bye handled client-side; else use it as user query
if result and result != "__STOP__":
    user_text = result
    user_txt_ph.info(f"B·∫°n n√≥i: {user_text}")
    answer = find_answer(user_text)
    assistant_txt_ph.success(f"Tr·ª£ l√Ω tr·∫£ l·ªùi: {answer}")
    # Now instruct client to speak the answer: we reuse experimental_set_query_params to send an action the JS will catch next render
    # encode the answer in query param (URL length limit; keep answers short). We'll set action=tts&text=...
    # To avoid URL length issues, we'll trigger play_intro-like behavior: set action=start_tts with text encoded in base64
    import base64
    b = base64.b64encode(answer.encode("utf-8")).decode("ascii")
    st.experimental_set_query_params(action="tts", payload=b)
    # The JS component doesn't currently handle tts via action=tts; so to keep it simple, show a 'Ph√°t l·ªùi ƒë√°p' button:
    if st.button("üîä Ph√°t l·ªùi ƒë√°p"):
        # instruct client to speak by setting action=tts - JS in component won't run again automatically, but we'll trigger by re-rendering the component with new params
        st.experimental_set_query_params(action="play_answer", payload=b)
        st.experimental_rerun()
